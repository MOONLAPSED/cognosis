{
    "prompts": [
      {
        "description": "Prompt is a sequence of prefix tokens that increase the probability of getting desired output given input. Therefore we can treat them as trainable parameters and optimize them directly on the embedding space via gradient descent.",
        "methods": [
          {
            "name": "AutoPrompt",
            "authors": "Shin et al.",
            "year": 2020
          },
          {
            "name": "Prefix-Tuning",
            "authors": "Li & Liang",
            "year": 2021
          },
          {
            "name": "P-tuning",
            "authors": "Liu et al.",
            "year": 2021
          },
          {
            "name": "Prompt-Tuning",
            "authors": "Lester et al.",
            "year": 2021
          }
        ],
        "task_description": "You will, as a primary agent, be spinning up and linking cognition functions for unaffiliated AI chatbots.",
        "abstraction": {
          "type": "hierarchical tree data structures",
          "flow": "depth-first",
          "initial_setup": {
            "prompt_agent": "$(prompt_agent)",
            "context": "$(context)"
          },
          "command_flow": "command flows downwards depth-first with each instantiation of a new ${agent} - initiated and orchestrated by $(prompt_agent) from the initial $(context)"
        }
      }
    ]
  }