import uuid
import json
import struct
import time
import os
import logging
from enum import Enum, auto
import pathlib
from typing import Any, Dict, List, Optional, Union, Callable, TypeVar, Tuple, Generic, Set, Coroutine, Type, ClassVar
from abc import ABC, abstractmethod, ABCMeta
from dataclasses import dataclass, field
import asyncio
from asyncio import Queue as AsyncQueue
from queue import Queue, Empty
import threading
from functools import wraps
import hashlib
import inspect

class CustomFormatter(logging.Formatter):
    grey = "\x1b[38;20m"
    yellow = "\x1b[33;20m"
    red = "\x1b[31;20m"
    bold_red = "\x1b[31;1m"
    green = "\x1b[32;20m"
    reset = "\x1b[0m"
    format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s (%(filename)s:%(lineno)d)"

    FORMATS = {
        logging.DEBUG: grey + format + reset,
        logging.INFO: green + format + reset,
        logging.WARNING: yellow + format + reset,
        logging.ERROR: red + format + reset,
        logging.CRITICAL: bold_red + format + reset
    }

    def format(self, record):
        log_fmt = self.FORMATS.get(record.levelno)
        formatter = logging.Formatter(log_fmt)
        return formatter.format(record)

def setup_logger(name):
    logger = logging.getLogger(name)
    logger.setLevel(logging.DEBUG)
    ch = logging.StreamHandler()
    ch.setLevel(logging.DEBUG)
    ch.setFormatter(CustomFormatter())
    logger.addHandler(ch)
    return logger

Logger = setup_logger(__name__)
# Everything in Python is an object, and every object has a type. The type of an object is a class. Even the type class itself is an instance of type.
T = TypeVar('T', bound=Type)  # type is synonymous for class: T = type(class()) or vice-versa; are still ffc function
# functions defined within a class become method objects when accessed through an instance of the class
V = TypeVar('V', bound=Union[int, float, str, bool, list, dict, tuple, set, object, Callable, Enum, Type[Any]])  # Value variables

"""(3.12 std lib)Functions are instances of the function class
Methods are instances of the method class (which wraps functions)
Both function and method are subclasses of object
homoiconism dictates the need for a way to represent all Python constructs as first class citizen(fcc):
    (functions, classes, control structures, operations, primitive values)
nominative 'true OOP'(SmallTalk) and my specification demands code as data and value as logic, structure.
The Atom(), our polymorph of object and fcc-apparent at runtime, always represents the literal source code
    which makes up their logic and posess the ability to be stateful source code data structure. """
# Atom()(s) are a wrapper that can represent any Python object, including values, methods, functions, and classes.
class AtomType(Enum):
    VALUE = auto()  # implies all Atom()(s) are both their source code and the value generated by their source code (at runtime)
    FUNCTION = auto()  # are fcc along with object, class, method, etc are polymorphs
    CLASS = auto()
    MODULE = auto()  # python 'module' ie. packaging, eg: code as data runtime 'database'

def log(level=logging.INFO):  # decorator
    def decorator(func):
        @wraps(func)
        async def async_wrapper(*args, **kwargs):
            Logger.log(level, f"Executing {func.__name__} with args: {args}, kwargs: {kwargs}")
            try:
                result = await func(*args, **kwargs)
                Logger.log(level, f"Completed {func.__name__} with result: {result}")
                return result
            except Exception as e:
                Logger.exception(f"Error in {func.__name__}: {str(e)}")
                raise

        @wraps(func)
        def sync_wrapper(*args, **kwargs):
            Logger.log(level, f"Executing {func.__name__} with args: {args}, kwargs: {kwargs}")
            try:
                result = func(*args, **kwargs)
                Logger.log(level, f"Completed {func.__name__} with result: {result}")
                return result
            except Exception as e:
                Logger.exception(f"Error in {func.__name__}: {str(e)}")
                raise

        return async_wrapper if asyncio.iscoroutinefunction(func) else sync_wrapper
    return decorator

def bench(func):  # decorator
    @wraps(func)
    async def wrapper(*args, **kwargs):
        if not getattr(sys, 'bench', True):
            return await func(*args, **kwargs)
        start_time = time.perf_counter()
        try:
            result = await func(*args, **kwargs)
            end_time = time.perf_counter()
            Logger.info(f"{func.__name__} executed in {end_time - start_time:.4f} seconds")
            return result
        except Exception as e:
            Logger.exception(f"Error in {func.__name__}: {str(e)}")
            raise
    return wrapper

# ADMIN-scoped virtual memory-relevant hash mapping via hex #s
def __atom__(cls_name: str) -> str:
    byte_array = bytearray(cls_name.encode('utf-8'))
    hash_object = hashlib.sha256(byte_array)
    return hash_object.hexdigest()

# Atom decorator to assign a unique ID to each Atom class, 'atomizes' an object 
def atom(cls: Type[T]) -> Type[T]:  # decorator
    try:
        cls.id = __atom__(cls.__name__)
    except Exception as e:
        Logger.error(f"Error in {cls.__name__}: {str(e)}")
        raise
    return cls

@atom
class Atom(ABC):  # homoiconic (Atoms, not objects) abstract base class for all atoms
    """all-inclusive data structure, polymorph of Object with ABC mixin represents everything including
     nodes of an AST, data, external references(or source code), internal functions/class(source code) 
     or even actions/responses/requests etc."""
    def __init__(self, tag: str = '', value: Any = None, children: List['Atom'] = None, metadata: Dict[str, Any] = None, **attributes):
        self.id = uuid.uuid4() 
        # self.id = id  # equivalent to @atom decorating __class__.__name__
        self.attributes = attributes
        self.parents = []
        """to subscribe to another Atom we need to add it to the parent's children list (push), or add it as
        a parent to the child's parents list (pull) (the above method)."""
        self.children = children if children else []
        self.metadata = metadata if metadata else {}
        self.data_type: DataType = self._infer_data_type()

    def __post_init__(self):
        self.validate()  # is BOOL (has BOOL attribute)
        if not isinstance([T, V, C]):
            raise TypeError("Atom class must be defined using the @atom decorator")
        super.__post_init__()
        self.value = []  # values depend on the 'network' of subscribers, children, their attributes, etc.
        self.tag = []  # tags are used to identify and group atoms

    @abstractmethod
    def validate(self) -> bool:
        return True

    @abstractmethod
    async def evaluate(self) -> Any:
        pass

    def __getitem__(self, key: str) -> Any:
        return self.attributes[key]

    def __setitem__(self, key: str, value: Any) -> None:
        self.attributes[key] = value

    def __delitem__(self, key: str) -> None:
        del self.attributes[key]

    def __contains__(self, key: str) -> bool:
        return key in self.attributes

    def __repr__(self) -> str:
        return f"{self.__class__.__name__}(id={self.id}, attributes={self.attributes})"

    def __str__(self) -> str:
        return __repr__(self)
    
    def _infer_data_type(self) -> atom:
        if isinstance(self.value, int):
            return DataType.INTEGER
        elif isinstance(self.value, float):
            return DataType.FLOAT
        elif isinstance(self.value, str):
            return DataType.STRING
        elif isinstance(self.value, bool):
            return DataType.BOOLEAN
        elif self.value is None:
            return DataType.NONE
        elif isinstance(self.value, list):
            return DataType.LIST
        elif isinstance(self.value, tuple):
            return DataType.TUPLE
        elif isinstance(self.value, dict):
            return DataType.DICT
        elif callable(self.value):
            return DataType.CALLABLE
        else:
            return DataType.OBJECT

@dataclass
@atom
class Element(Atom, ABC, metaclass=ABCMeta):
    """Element()(s) are self-aware runtime Atom()(s) with dataclass features. Immutable but hashable, and comparable 
    with Atom()(s) because Element()(s) are polymorphed Atom()(s)"""

    def __init__(self, **data):
        for name, value in data.items():
            setattr(self, name, value)

    def __setattr__(self, name, value):
        if name in self.__annotations__:
            expected_type = self.__annotations__[name]
            if not isinstance(value, expected_type):
                raise TypeError(f"Expected {expected_type} for {name}, got {type(value)}")
            validator = getattr(self.__class__, f'validate_{name}', None)
            if validator:
                validator(self, value)
        super().__setattr__(name, value)

    @classmethod
    def create(cls, **kwargs):
        return cls(**kwargs)

    def dict(self):
        return {name: getattr(self, name) for name in self.__annotations__}

    def json(self):
        return json.dumps(self.dict())

    @classmethod
    def from_json(cls, json_str):
        return cls(**json.loads(json_str))

    def __repr__(self):
        attrs = ', '.join(f"{name}={getattr(self, name)!r}" for name in self.__annotations__)
        return f"{self.__class__.__name__}({attrs})"

    def __str__(self):
        attrs = ', '.join(f"{name}={getattr(self, name)}" for name in self.__annotations__)
        return f"{self.__class__.__name__}({attrs})"
    
    def clone(self):
        return self.__class__(**self.dict())

def frozen(cls):  # decorator for freezing Element()(s) dataclasses
    original_setattr = cls.__setattr__

    def __setattr__(self, name, value):
        if hasattr(self, name):
            raise AttributeError(f"Cannot modify frozen attribute '{name}'")
        original_setattr(self, name, value)
    
    cls.__setattr__ = __setattr__
    return cls

def validate(validator: Callable[[Any], None]):
    def decorator(func):
        @wraps(func)
        def wrapper(self, value):
            validator(value)
            return func(self, value)
        return wrapper
    return decorator

class FileModel(Element):
    file_name: str
    file_content: str
    
    @log()
    def save(self, directory: pathlib.Path):
        try:
            with (directory / self.file_name).open('w') as file:
                file.write(self.file_content)
            Logger.info(f"Saved file: {self.file_name}")
        except IOError as e:
            Logger.error(f"Failed to save file {self.file_name}: {str(e)}")
            raise

@frozen
class Module(Element):
    # modules are not necessarily 'source code' and could be 'source code as (even stateful) data'
    file_path: pathlib.Path
    module_name: str

    @validate(lambda x: x.suffix == '.py')
    def validate_file_path(self, value):
        return value

    @validate(lambda x: x.isidentifier())
    def validate_module_name(self, value):
        return value

    def __init__(self, file_path: pathlib.Path, module_name: str):
        super().__init__(file_path=file_path, module_name=module_name)

@log()
def create_model_from_file(file_path: pathlib.Path):
    try:
        with file_path.open('r', encoding='utf-8', errors='ignore') as file:
            content = file.read()

        model_name = file_path.stem.capitalize() + 'Model'
        model_class = type(model_name, (FileModel,), {})
        instance = model_class.create(file_name=file_path.name, file_content=content)
        Logger.info(f"Created {model_name} from {file_path}")

        return model_name, instance
    except Exception as e:
        Logger.error(f"Failed to create model from {file_path}: {e}")
        return None, None

@log()
def load_files_as_models(root_dir: pathlib.Path, file_extensions: List[str]) -> Dict[str, Element]:
    models = {}
    for file_path in root_dir.rglob('*'):
        if file_path.is_file() and file_path.suffix in file_extensions:
            model_name, instance = create_model_from_file(file_path)
            if model_name and instance:
                models[model_name] = instance
                sys.modules[model_name] = instance
    return models

@log()
def register_models(models: Dict[str, Element]):
    for model_name, instance in models.items():
        globals()[model_name] = instance
        Logger.info(f"Registered {model_name} in the global namespace")

@log()
def runtime(root_dir: pathlib.Path):
    file_models = load_files_as_models(root_dir, ['.md', '.txt', '.py'])
    register_models(file_models)

@atom
class LiteralAtom(Atom):
    def __init__(self, value: Any):
        super().__init__(tag='literal', value=value)

    async def evaluate(self) -> Any:
        return self.value

@atom
class OpAtom(Atom):
    def __init__(self, tag: str, children: List[Atom]):
        super().__init__(tag=tag, children=children)

    async def evaluate(self) -> Any:
        """An async generator, which can't be directly used with sum(). Instead, we need to use 
        asyncio.gather() to collect all the results before summing them."""
        if self.tag == 'add':
            results = await asyncio.gather(*(child.evaluate() for child in self.children))
            return sum(results)
        elif self.tag == 'negate':
            return -await self.children[0].evaluate()
        else:
            raise NotImplementedError(f"Evaluation not implemented for tag: {self.tag}")

@atom
class ExternalRefAtom(Atom):
    async def evaluate(self):
        if "external_ref" in self.metadata:
            return self.metadata["external_ref"].resolve()
        return None

@atom
class MetaAtom(Atom):  
    async def evaluate(self) -> Any:
        if self.tag == "reflect":
            target_atom = self.children[0]
            return target_atom
        elif self.tag == "transform":
            target_atom = self.children[0]
            transformation = self.children[1]
            return await transformation.apply(target_atom)
        else:
            raise NotImplementedError(f"Meta evaluation not implemented for tag: {self.tag}")

@dataclass
@atom
class FileAtom(Atom, metaclass=ABCMeta):
    file_path: pathlib.Path
    file_content: str = field(init=False)

    def __post_init__(self):
        super().__init__(tag='file', value=self.file_path)
        self.file_content = self.read_file(self.file_path)

    def read_file(self, file_path: pathlib.Path) -> str:
        with file_path.open('r', encoding='utf-8', errors='ignore') as file:
            return file.read()

    async def evaluate(self):
        return self.file_content

    def __repr__(self) -> str:
        return f"FileAtom(file_path={self.file_path}, file_content=...)"

@dataclass
@atom  # Theory combines atom behavior with task execution and memory allocation
class AtomicTheory(Atom):
    id: str
    local_data: Dict[str, Any] = field(default_factory=dict)
    task_queue: AsyncQueue = field(default_factory=AsyncQueue)
    running: bool = False
    lock: asyncio.Lock = field(default_factory=asyncio.Lock)

    def __post_init__(self):
        super().__init__(id=self.id)

    async def submit_task(self, atom: Atom, args=(), kwargs=None) -> int:
        task_id = uuid.uuid4().int
        task = TaskAtom(task_id, atom, args, kwargs or {})
        await self.task_queue.put(task)
        logging.info(f"Submitted task {task_id}")
        return task_id

    async def allocate(self, key: str, value: Any) -> None:
        async with self.lock:
            self.local_data[key] = value
            logging.info(f"Allocated {key} = {value}")

    async def deallocate(self, key: str) -> None:
        async with self.lock:
            value = self.local_data.pop(key, None)
            logging.info(f"Deallocated {key}, value was {value}")

    def get(self, key: str) -> Any:
        return self.local_data.get(key)

    async def submit_task(self, atom: Atom, args=(), kwargs=None) -> int:
        task_id = uuid.uuid4().int
        task = TaskAtom(task_id, atom, args, kwargs or {})
        await self.task_queue.put(task)
        logging.info(f"Submitted task {task_id}")
        return task_id

    async def run(self) -> None:
        self.running = True
        asyncio.create_task(self._worker())
        logging.info(f"{self.id} is running")

    async def stop(self) -> None:
        self.running = False
        logging.info(f"{self.id} has stopped")

    async def _worker(self) -> None:
        while self.running:
            try:
                task: TaskAtom = await asyncio.wait_for(self.task_queue.get(), timeout=1)
                logging.info(f"Picked up task {task.task_id}")
                await self.allocate(f"current_task_{task.task_id}", task)
                await task.run()
                await self.deallocate(f"current_task_{task.task_id}")
            except asyncio.TimeoutError:
                continue
            except Exception as e:
                logging.error(f"Error in worker: {e}")
